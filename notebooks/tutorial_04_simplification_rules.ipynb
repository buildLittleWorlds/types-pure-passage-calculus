{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 4: Simplification Rules\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/buildLittleWorlds/types-pure-passage-calculus/blob/main/notebooks/tutorial_04_simplification_rules.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "## When Is a Passage Fully Simplified?\n",
    "\n",
    "In Year 731, Kelleth Mund's treatise *The Passage Calculus* introduced the concept of **normal form**:\n",
    "\n",
    "> *\"A passage is in normal form when no further simplification is possible. It has reached its essential structure.\"*\n",
    "\n",
    "This tutorial explores the rules that govern simplification and when passages are considered \"done.\"\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will:\n",
    "1. Identify passages in **normal form**\n",
    "2. Distinguish **weak head normal form** from **normal form**\n",
    "3. Understand **eta reduction**\n",
    "4. Analyze reduction behavior using the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BASE_URL = \"https://raw.githubusercontent.com/buildLittleWorlds/densworld-datasets/main/data/\"\n",
    "\n",
    "reductions = pd.read_csv(BASE_URL + \"passage_reductions.csv\")\n",
    "\n",
    "print(f\"Loaded {len(reductions)} reduction steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: What Is Normal Form?\n",
    "\n",
    "A passage is in **normal form** (NF) when it contains no redexes—no subexpressions of the form `(λx.body) arg`.\n",
    "\n",
    "### Examples\n",
    "\n",
    "**In normal form:**\n",
    "- `x` (just a variable)\n",
    "- `λx.x` (abstraction, no redex inside)\n",
    "- `λx.λy.x` (nested abstractions, no redexes)\n",
    "- `x y` (application, but neither part is a λ)\n",
    "\n",
    "**NOT in normal form:**\n",
    "- `(λx.x) y` (this is a redex!)\n",
    "- `λz.((λx.x) z)` (contains a redex inside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all reduction steps that reach normal form\n",
    "normal_forms = reductions[reductions['is_normal_form'] == True]\n",
    "print(f\"Steps reaching normal form: {len(normal_forms)}\")\n",
    "normal_forms[['reduction_id', 'expression_after', 'total_steps', 'notes']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What kinds of expressions end up in normal form?\n",
    "# Let's categorize by what the final expression looks like\n",
    "\n",
    "def categorize_normal_form(expr):\n",
    "    expr = str(expr).strip()\n",
    "    if expr.startswith('λ') or expr.startswith('(λ'):\n",
    "        return 'abstraction'\n",
    "    elif len(expr) == 1 and expr.isalpha():\n",
    "        return 'variable'\n",
    "    elif '(' in expr:\n",
    "        return 'application'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "normal_forms['nf_type'] = normal_forms['expression_after'].apply(categorize_normal_form)\n",
    "normal_forms['nf_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Weak Head Normal Form (WHNF)\n",
    "\n",
    "Sometimes we don't need to fully reduce an expression. **Weak Head Normal Form** is reached when:\n",
    "- The expression is a λ-abstraction, OR\n",
    "- The expression is an application where the function is not a λ\n",
    "\n",
    "WHNF stops as soon as we can't reduce the \"head\" (outermost) position.\n",
    "\n",
    "### Example\n",
    "\n",
    "`λz.((λx.x) z)` is in WHNF (it's a λ) but NOT in normal form (the body contains a redex)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Many functional languages (Haskell) use WHNF for lazy evaluation\n",
    "# Let's look at cases where the Theta combinator reaches WHNF\n",
    "\n",
    "theta_traces = reductions[reductions['notes'].str.contains('Theta|weak head', case=False, na=False)]\n",
    "theta_traces[['reduction_id', 'expression_after', 'is_normal_form', 'notes']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Eta Reduction\n",
    "\n",
    "Besides beta reduction, there's another simplification: **eta reduction**.\n",
    "\n",
    "The eta rule:\n",
    "```\n",
    "λx.(f x)  →  f    (when x is not free in f)\n",
    "```\n",
    "\n",
    "This says: if a function just applies `f` to its argument, it's the same as `f`.\n",
    "\n",
    "### Example\n",
    "- `λx.(add x)` eta-reduces to `add`\n",
    "- `λx.((λy.y) x)` can first beta-reduce the inner part, then eta-reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find eta reductions in the data\n",
    "eta_steps = reductions[reductions['rule_applied'] == 'eta']\n",
    "print(f\"Eta reduction steps: {len(eta_steps)}\")\n",
    "eta_steps[['reduction_id', 'expression_after', 'notes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eta equivalence in Python\n",
    "def add(x):\n",
    "    return x + 1\n",
    "\n",
    "# These are eta-equivalent:\n",
    "f1 = add\n",
    "f2 = lambda x: add(x)\n",
    "\n",
    "print(f\"add(5) = {add(5)}\")\n",
    "print(f\"(λx.add x)(5) = {f2(5)}\")\n",
    "print(f\"Same result: {add(5) == f2(5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Non-Termination\n",
    "\n",
    "Not all expressions have a normal form. Some reduce forever.\n",
    "\n",
    "The classic example is **Omega**:\n",
    "```\n",
    "Ω = (λx.x x)(λx.x x)\n",
    "  → (λx.x x)(λx.x x)\n",
    "  → (λx.x x)(λx.x x)\n",
    "  → ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find non-terminating reductions\n",
    "non_terminating = reductions[reductions['terminates'] == False].drop_duplicates('reduction_id')\n",
    "print(f\"Non-terminating expressions: {len(non_terminating)}\")\n",
    "non_terminating[['reduction_id', 'initial_expression', 'notes']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Omega reduction\n",
    "omega_trace = reductions[reductions['reduction_id'] == 'PR-009']\n",
    "omega_trace[['step_number', 'expression_after', 'terminates', 'notes']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Non-Termination Matters\n",
    "\n",
    "Non-termination is related to the Great Categorical Collapse. When documents could reference themselves in certain ways, the Archive's indexing system would loop forever—just like Omega."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But not all self-reference leads to non-termination!\n",
    "# The Y combinator enables useful recursion\n",
    "\n",
    "# Find Y combinator traces\n",
    "y_traces = reductions[reductions['notes'].str.contains('Y comb', case=False, na=False)]\n",
    "y_traces[['reduction_id', 'initial_expression', 'terminates', 'notes']].drop_duplicates('reduction_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Reduction Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many reductions terminate vs don't?\n",
    "final_steps = reductions[reductions['is_normal_form'] == True]\n",
    "termination_counts = final_steps['terminates'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "termination_counts.plot(kind='bar', color=['steelblue', 'coral'])\n",
    "plt.title('Terminating vs Non-Terminating Expressions')\n",
    "plt.xlabel('Terminates')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What rules are applied most often?\n",
    "reductions['rule_applied'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average steps by termination status\n",
    "terminating = final_steps[final_steps['terminates'] == True]\n",
    "\n",
    "print(f\"Average steps for terminating expressions: {terminating['total_steps'].mean():.1f}\")\n",
    "print(f\"Max steps for terminating expressions: {terminating['total_steps'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the longest terminating reduction?\n",
    "longest = terminating[terminating['total_steps'] == terminating['total_steps'].max()]\n",
    "longest[['reduction_id', 'initial_expression', 'total_steps', 'notes']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Normal vs Applicative Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some expressions terminate in normal order but not applicative order\n",
    "\n",
    "# K = λx.λy.x (returns first argument, ignores second)\n",
    "# Ω = (λx.x x)(λx.x x) (never terminates)\n",
    "\n",
    "# Normal order: (K a) Ω → a  (never evaluates Ω)\n",
    "# Applicative order: (K a) Ω → stuck trying to evaluate Ω\n",
    "\n",
    "strategy_examples = reductions[reductions['notes'].str.contains('Normal order|Applicative', case=False, na=False)]\n",
    "strategy_examples[['reduction_id', 'initial_expression', 'terminates', 'notes']].drop_duplicates('reduction_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python uses applicative order (eager evaluation)\n",
    "# This is why we can't directly implement lazy lambda calculus\n",
    "\n",
    "def K(x):\n",
    "    return lambda y: x\n",
    "\n",
    "def omega():\n",
    "    while True:\n",
    "        pass  # Infinite loop\n",
    "\n",
    "# This would hang in Python:\n",
    "# K(5)(omega())  # Python tries to evaluate omega() first!\n",
    "\n",
    "# But this works:\n",
    "print(K(5)(lambda: None))  # Passing a function, not calling it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 1: Identify Normal Forms\n",
    "\n",
    "Which of these are in normal form?\n",
    "\n",
    "1. `λx.x`\n",
    "2. `(λx.x) y`\n",
    "3. `x y`\n",
    "4. `λf.λx.f (f x)`\n",
    "5. `λx.((λy.y) x)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1 workspace\n",
    "\n",
    "# 1. λx.x - In NF? \n",
    "#    Is there a redex (λ..)arg anywhere?\n",
    "\n",
    "# 2. (λx.x) y - In NF?\n",
    "#    This IS a redex...\n",
    "\n",
    "# 3. x y - In NF?\n",
    "#    Neither x nor y is a λ...\n",
    "\n",
    "# 4. λf.λx.f (f x) - In NF?\n",
    "#    Look inside the body...\n",
    "\n",
    "# 5. λx.((λy.y) x) - In NF?\n",
    "#    The body contains..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Eta Reduction\n",
    "\n",
    "Which can be eta-reduced? If so, to what?\n",
    "\n",
    "1. `λx.(f x)`\n",
    "2. `λx.(x x)`\n",
    "3. `λx.((g y) x)`\n",
    "4. `λx.(f x y)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2 workspace\n",
    "\n",
    "# Eta rule: λx.(f x) → f when x not free in f\n",
    "\n",
    "# 1. λx.(f x)\n",
    "#    Is x free in f? No (f is just a variable)\n",
    "#    → f\n",
    "\n",
    "# 2. λx.(x x)\n",
    "#    This is NOT of the form λx.(f x) where f doesn't contain x\n",
    "#    The first x IS x, which we're abstracting over\n",
    "\n",
    "# 3. λx.((g y) x)\n",
    "#    Is this λx.(f x) where f = (g y)?\n",
    "\n",
    "# 4. λx.(f x y)\n",
    "#    This is λx.((f x) y), not λx.(f x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Analyze Reduction Patterns\n",
    "\n",
    "Using the reductions dataset:\n",
    "1. Find all unique expressions that reduce to just a variable\n",
    "2. Find the expression with the most reduction steps\n",
    "3. Calculate the percentage of expressions that terminate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3 workspace\n",
    "\n",
    "# 1. Expressions reducing to a variable\n",
    "# Hint: filter is_normal_form==True, then check if expression_after is a single letter\n",
    "\n",
    "# 2. Most reduction steps\n",
    "# Hint: find max of total_steps for terminating expressions\n",
    "\n",
    "# 3. Termination percentage\n",
    "# Hint: count terminates==True vs total unique reduction_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we learned:\n",
    "\n",
    "1. **Normal form** means no redexes remain—fully simplified\n",
    "2. **Weak head normal form (WHNF)** stops when the head can't reduce\n",
    "3. **Eta reduction** `λx.(f x) → f` removes pointless wrapping\n",
    "4. **Non-termination** occurs when reductions loop forever (like Omega)\n",
    "5. **Normal order** can find normal forms that applicative order misses\n",
    "\n",
    "### Next Tutorial\n",
    "\n",
    "In Tutorial 5, we'll discover that **everything can be encoded as passages**—numbers, booleans, pairs, and lists. This is Mund's most remarkable insight: objects are unnecessary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
